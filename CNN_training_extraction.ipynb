{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from custom_dataset import Binary_Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from inception import inception_v3\n",
    "from Trainer import train_loop\n",
    "from torch.optim import Adam\n",
    "%matplotlib inline\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataloaders for each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0])\n"
     ]
    }
   ],
   "source": [
    "#define relevant paths\n",
    "labels_dir=\"Data\\list_attr_celeba.csv\"\n",
    "image_dir=\"Data\\img_align_celeba\\img_align_celeba\"\n",
    "\n",
    "############################################define batch size for all data loaders here\n",
    "bathsize=50\n",
    "\n",
    "##############################################define num workers for data laoders here\n",
    "workers=4\n",
    "\n",
    "#define composed transforms\n",
    "composed = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([299,299]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "labels=[\"No_Beard\",\"Male\",\"Bald\",\"Bangs\",\"Smiling\"]\n",
    "label_number=1\n",
    "#Choose which label \n",
    "ds=Binary_Dataset(labels_dir, labels[label_number],image_dir ,transform=composed, partition=\"Train\")\n",
    "dataset_loader=DataLoader(ds,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "ds_val=Binary_Dataset(labels_dir, labels[label_number],image_dir ,transform=composed, partition=\"Val\")\n",
    "val_loader=DataLoader(ds_val,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "\"\"\"\n",
    "# male\n",
    "ds1=Binary_Dataset(labels_dir, labels[1],image_dir ,transform=composed)\n",
    "dataset_loader=DataLoader(ds1,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "# bald\n",
    "ds2=Binary_Dataset(labels_dir, labels[2],image_dir ,transform=composed)\n",
    "dataset_loader=DataLoader(ds2,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "# bangs\n",
    "ds3=Binary_Dataset(labels_dir, labels[3],image_dir ,transform=composed)\n",
    "dataset_loader=DataLoader(ds3,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "# smiling\n",
    "ds4=Binary_Dataset(labels_dir, labels[4],image_dir ,transform=composed)\n",
    "dataset_loader=DataLoader(ds4,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "for idx, (data, image) in enumerate(ds):\n",
    "    print(idx)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "data=next(iter(dataset_loader))\n",
    "sample, target = data\n",
    "#print(sample)\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#wont work anymore because pil\\nidx=0\\nplt.imshow(sample[idx])\\nprint(labels[label_number])\\nprint(target[idx])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#wont work anymore because pil\n",
    "idx=0\n",
    "plt.imshow(sample[idx])\n",
    "print(labels[label_number])\n",
    "print(target[idx])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CNN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DeepLearning_Project\\inception.py:81: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=inception_v3(pretrained=False).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(107.2329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.0897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.1725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.7932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.1580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.1050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.3935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.1908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.5744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.1579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.0962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.7968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.8854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.5776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.6587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.7661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.2623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.6736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.0600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.1996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.4724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.6528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.6950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.7938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.3547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.1817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.4095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.0980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.3505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.3029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.1559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.3139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.4433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.0579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.7856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.0987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.3216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.5276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.8751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.2972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.1528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.3227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.6470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.8297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.7372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.1533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.4363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.3051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.3816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.6856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.9584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.1013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.3578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.7948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.1135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.3127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.1983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.9383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.5862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.8191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.1597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.5170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.9518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.0935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.7473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.5492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.4057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.1375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.5851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.2825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.1312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.5458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.0561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.6165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.9398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.1057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.1578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.1508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.6794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.8641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.1180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.1659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.0591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.0741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.0964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.8394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.9136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.5077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.8737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.9338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.6270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.8482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.8450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.7054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.1284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.4962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.7936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.7836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.4152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.4480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.0857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.8278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.0416, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.2223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.2543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.2249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.8178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.8290, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.0001\n",
    "save_name=\"Male_12_8_e5\"\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "train_loop(model=model,dataloader=dataset_loader,epochs=5,optimizer=optimizer,save_name=\"Male_12_8_e5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntorch.load(\"Male_12_8.pt\") #insert name here\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "\"\"\"\n",
    "torch.load(\"Male_12_8.pt\") #insert name here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50)\n",
      "tensor(100)\n",
      "tensor(147)\n",
      "tensor(195)\n",
      "tensor(245)\n",
      "tensor(295)\n",
      "tensor(341)\n",
      "tensor(390)\n",
      "tensor(439)\n",
      "tensor(487)\n",
      "tensor(537)\n",
      "tensor(585)\n",
      "tensor(635)\n",
      "tensor(684)\n",
      "tensor(734)\n",
      "tensor(783)\n",
      "tensor(831)\n",
      "tensor(881)\n",
      "tensor(930)\n",
      "tensor(980)\n",
      "tensor(1029)\n",
      "tensor(1078)\n",
      "tensor(1127)\n",
      "tensor(1176)\n",
      "tensor(1226)\n",
      "tensor(1275)\n",
      "tensor(1325)\n",
      "tensor(1374)\n",
      "tensor(1423)\n",
      "tensor(1473)\n",
      "tensor(1523)\n",
      "tensor(1573)\n",
      "tensor(1623)\n",
      "tensor(1672)\n",
      "tensor(1722)\n",
      "tensor(1772)\n",
      "tensor(1821)\n",
      "tensor(1870)\n",
      "tensor(1920)\n",
      "tensor(1969)\n",
      "0.9834146341463414\n"
     ]
    }
   ],
   "source": [
    "#check validation accuracy\n",
    "ds_val=Binary_Dataset(labels_dir, labels[label_number],image_dir ,transform=composed, partition=\"Val\")\n",
    "val_loader=DataLoader(ds_val,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "device = torch.device(\"cpu\")\n",
    "val_data=iter(val_loader)\n",
    "model=model.to(device)\n",
    "correct=0\n",
    "tested_samples=0\n",
    "limit=2000\n",
    "for data in val_data:\n",
    "    sample, target = data\n",
    "    \n",
    "    #send to device\n",
    "    sample=sample.to(device)\n",
    "    target=target.to(device)\n",
    "\n",
    "    pred=torch.argmax(model(sample),dim=1,keepdim=True)\n",
    "\n",
    "    correct+=torch.eq(pred,target.view_as(pred)).sum()\n",
    "    tested_samples+=pred.size()[0]\n",
    "    if tested_samples>limit:\n",
    "        break\n",
    "\n",
    "    print(correct)\n",
    "\n",
    "#print precision\n",
    "print(correct.item()/tested_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"12_9_5e.pt\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
