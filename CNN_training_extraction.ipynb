{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from custom_dataset import Binary_Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from inception import inception_v3\n",
    "from Trainer import train_loop\n",
    "from torch.optim import Adam\n",
    "%matplotlib inline\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "source": [
    "# Define Dataloaders for each class\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n        0, 0, 0, 1, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "#define relevant paths\n",
    "labels_dir=\"Data\\list_attr_celeba.csv\"\n",
    "image_dir=\"Data\\img_align_celeba\\img_align_celeba\"\n",
    "\n",
    "############################################define batch size for all data loaders here\n",
    "bathsize=32\n",
    "\n",
    "##############################################define num workers for data laoders here\n",
    "workers=4\n",
    "\n",
    "#define composed transforms\n",
    "composed = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([299,299]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "labels=[\"No_Beard\",\"Male\",\"Bald\",\"Bangs\",\"Smiling\"]\n",
    "label_number=1\n",
    "#Choose which label \n",
    "ds=Binary_Dataset(labels_dir, labels[label_number],image_dir ,transform=composed, partition=\"Train\")\n",
    "dataset_loader=DataLoader(ds,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "ds_val=Binary_Dataset(labels_dir, labels[label_number],image_dir ,transform=composed, partition=\"Val\")\n",
    "val_loader=DataLoader(ds_val,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "\"\"\"\n",
    "# male\n",
    "ds1=Binary_Dataset(labels_dir, labels[1],image_dir ,transform=composed)\n",
    "dataset_loader=DataLoader(ds1,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "# bald\n",
    "ds2=Binary_Dataset(labels_dir, labels[2],image_dir ,transform=composed)\n",
    "dataset_loader=DataLoader(ds2,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "# bangs\n",
    "ds3=Binary_Dataset(labels_dir, labels[3],image_dir ,transform=composed)\n",
    "dataset_loader=DataLoader(ds3,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "# smiling\n",
    "ds4=Binary_Dataset(labels_dir, labels[4],image_dir ,transform=composed)\n",
    "dataset_loader=DataLoader(ds4,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "for idx, (data, image) in enumerate(ds):\n",
    "    print(idx)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "data=next(iter(dataset_loader))\n",
    "sample, target = data\n",
    "#print(sample)\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n#wont work anymore because pil\\nidx=0\\nplt.imshow(sample[idx])\\nprint(labels[label_number])\\nprint(target[idx])\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "\"\"\"\n",
    "#wont work anymore because pil\n",
    "idx=0\n",
    "plt.imshow(sample[idx])\n",
    "print(labels[label_number])\n",
    "print(target[idx])\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "# Define CNN's"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=inception_v3(pretrained=False).to(device)"
   ]
  },
  {
   "source": [
    "# Training Loop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(125.0629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.4640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.4030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.2239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.8113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.3148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.1976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.5639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.0564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.8872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.1163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.0326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.0632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.7323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.7831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.2856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.4417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.7527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.1676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.2934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.8325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.4757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.3553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.6093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.6345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.9789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.3159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.9704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.8130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.6056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.1607, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-606748846506>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Male_12_8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\DeepLearning_Project\\Trainer.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(model, dataloader, epochs, optimizer, save_name)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m#print(target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate=0.0001\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "train_loop(model=model,dataloader=dataset_loader,epochs=1,optimizer=optimizer,save_name=\"Male_12_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(30)\n",
      "tensor(59)\n",
      "tensor(87)\n",
      "tensor(117)\n",
      "tensor(146)\n",
      "tensor(175)\n",
      "tensor(202)\n",
      "tensor(230)\n",
      "tensor(260)\n",
      "tensor(287)\n",
      "tensor(315)\n",
      "tensor(344)\n",
      "tensor(373)\n",
      "tensor(402)\n",
      "tensor(432)\n",
      "tensor(459)\n",
      "tensor(489)\n",
      "tensor(517)\n",
      "tensor(543)\n",
      "tensor(572)\n",
      "tensor(602)\n",
      "tensor(629)\n",
      "tensor(658)\n",
      "tensor(687)\n",
      "tensor(716)\n",
      "tensor(746)\n",
      "tensor(776)\n",
      "tensor(806)\n",
      "tensor(837)\n",
      "tensor(864)\n",
      "tensor(896)\n",
      "tensor(925)\n",
      "tensor(957)\n",
      "tensor(987)\n",
      "tensor(1016)\n",
      "tensor(1047)\n",
      "tensor(1076)\n",
      "tensor(1105)\n",
      "tensor(1134)\n",
      "tensor(1165)\n",
      "tensor(1195)\n",
      "tensor(1224)\n",
      "tensor(1252)\n",
      "tensor(1280)\n",
      "tensor(1309)\n",
      "tensor(1338)\n",
      "tensor(1367)\n",
      "tensor(1392)\n",
      "tensor(1421)\n",
      "tensor(1448)\n",
      "tensor(1475)\n",
      "tensor(1504)\n",
      "tensor(1532)\n",
      "tensor(1564)\n",
      "tensor(1594)\n",
      "tensor(1626)\n",
      "tensor(1655)\n",
      "tensor(1684)\n",
      "tensor(1712)\n",
      "tensor(1742)\n",
      "tensor(1773)\n",
      "tensor(1801)\n",
      "0.908234126984127\n"
     ]
    }
   ],
   "source": [
    "#check validation accuracy\n",
    "ds_val=Binary_Dataset(labels_dir, labels[label_number],image_dir ,transform=composed, partition=\"Val\")\n",
    "val_loader=DataLoader(ds_val,batch_size=bathsize, shuffle=True, num_workers=workers)\n",
    "device = torch.device(\"cpu\")\n",
    "val_data=iter(val_loader)\n",
    "model=model.to(device)\n",
    "correct=0\n",
    "tested_samples=0\n",
    "limit=2000\n",
    "for data in val_data:\n",
    "    sample, target = data\n",
    "    \n",
    "    #send to device\n",
    "    sample=sample.to(device)\n",
    "    target=target.to(device)\n",
    "\n",
    "    pred=torch.argmax(model(sample),dim=1,keepdim=True)\n",
    "\n",
    "    correct+=torch.eq(pred,target.view_as(pred)).sum()\n",
    "    tested_samples+=pred.size()[0]\n",
    "    if tested_samples>limit:\n",
    "        break\n",
    "\n",
    "    print(correct)\n",
    "\n",
    "#print precision\n",
    "print(correct.item()/tested_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6796875\n"
     ]
    }
   ],
   "source": []
  }
 ]
}